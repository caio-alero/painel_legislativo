footer = tabler_footer(
left = "Rstats, 2020",
right = a(href = "https://www.google.com")
)
)
)
server <- function(input, output) {}
shinyApp(ui, server)
# example with custom JS code to activate tabs
shinyAppDir(system.file("tabler/tabler_tabs", package = "OSUICode"))
}
if (interactive()) {
library(shiny)
# example without JS
ui <- tabler_page(
tabler_navbar(
brand_url = "https://preview-dev.tabler.io",
brand_image = "https://preview-dev.tabler.io/static/logo.svg",
nav_menu = tabler_navbar_menu(
tabler_navbar_menu_item(
text = "Tab 1",
icon = NULL,
tabName = "tab1",
selected = TRUE
),
tabler_navbar_menu_item(
text = "Tab 2",
icon = NULL,
tabName = "tab2"
)
)
),
tabler_body(
tabler_tab_items(
tabler_tab_item(
tabName = "tab1",
p("Hello World")
),
tabler_tab_item(
tabName = "tab2",
p("Second Tab")
)
),
footer = tabler_footer(
left = "Rstats, 2020",
right = a(href = "https://www.google.com")
)
)
)
server <- function(input, output) {}
shinyApp(ui, server)
# example with custom JS code to activate tabs
shinyAppDir(system.file("tabler/tabler_tabs", package = "OSUICode"))
}
runApp('C:/Users/caiol/Dropbox/ALE-RO/sapl app/shiny_sapl_2.R')
runApp('C:/Users/caiol/Dropbox/ALE-RO/sapl app/shiny_sapl_2.R')
runApp('C:/Users/caiol/Dropbox/ALE-RO/sapl app/shiny_sapl_2.R')
runApp('C:/Users/caiol/Dropbox/ALE-RO/sapl app/shiny_sapl_2.R')
runApp('C:/Users/caiol/Dropbox/ALE-RO/sapl app/shiny_sapl_2.R')
runApp('C:/Users/caiol/Dropbox/ALE-RO/sapl app/shiny_sapl_2.R')
library(shiny); runApp('C:/Users/caiol/Dropbox/ALE-RO/sapl app/shiny_sapl_2.R')
sapl_data <- readRDS(url('https://github.com/caio-alero/analise_sapl/blob/main/dados_sapl.rds?raw=TRUE'))
library(shiny); runApp('C:/Users/caiol/Dropbox/ALE-RO/sapl app/shiny_sapl_2.R')
runApp('C:/Users/caiol/Dropbox/ALE-RO/sapl app/shiny_sapl_2.R')
runApp('C:/Users/caiol/Dropbox/ALE-RO/sapl app/shiny_sapl_2.R')
runApp('C:/Users/caiol/Dropbox/ALE-RO/sapl app/shiny_sapl_2.R')
runApp('C:/Users/caiol/Dropbox/ALE-RO/sapl app/shiny_sapl_2.R')
source('shiny_sapl2.R')
runApp('C:/Users/caiol/Dropbox/ALE-RO/sapl app/global.R')
source('webscrapping\webscrapping_sessoes.R')
setwd("C:/Users/caiol/Dropbox/ALE-RO/sapl app")
source('webscrapping\webscrapping_sessoes.R')
source('webscrapping\\webscrapping_sessoes.R')
source('webscrapping\analise_textual_sapl.R')
source('webscrapping\\analise_textual_sapl.R')
source('analise_textual_sapl.R')
source('ui.R')
source('server.R')
ui
server
runApp()
library(rvest)      # web scrapping
library(dplyr)      # manipular dados
library(stringr)    # manipular os textos
library(xml2)       # ler html
library(jbkmisc)
library(tm)
# o cÃ³digo de scrape a seguir serve tanto para PLO como PLC
# tipos de materia: PLO, PLC, VP
# uma_pagina = TRUE ou FALSE
#sapl_scrap <- function(URL, tipo_materia = NULL, uma_pagina = FALSE) {
sapl_scrap <- function(URL, uma_pagina = FALSE) {
# extraindo o numero total de paginas
num_total_pages <- ifelse(uma_pagina,
1,
str_replace(URL, 'page=PAGE&', '') %>%
read_html() %>%
xml_find_all('//nav/ul') %>%
xml_text() %>%
str_clean() %>%
str_match_all('[0-9]+') %>%
unlist() %>%
as.numeric() %>%
max())
# scrapping das ementas
num_projeto <- list()
data_apresentacao <- list()
localizacao_atual <- list()
autor <- list()
ementas <- list()
status <- list()
data_ultima_tram <- list()
resultado <- list()
for(i in 1:num_total_pages) {
url <- str_replace(URL, 'PAGE', as.character(i))
pagina <- read_html(url) %>% xml_root()
# numero de materia
nodes_link <- xml_find_all(pagina, '//td//a')
#num_projeto[[i]] <- xml_text(nodes_link)[str_detect(xml_text(nodes_link), tipo_materia)]
num_projeto[[i]] <- xml_text(nodes_link)[!(xml_text(nodes_link) %in% c('Texto Original', '', 'Acompanhar MatÃ©ria'))]
num_projeto[[i]] <- num_projeto[[i]][!str_detect(num_projeto[[i]], pattern = '\n')]
# textos
textos <- xml_find_all(pagina, '//td') %>%
xml_text() %>%
str_clean()
textos <- textos[textos != ' ']
textos <- textos[-1]
#-----------------------------------------------------------------------------------------------------------
#                 data de apresentacao
#-----------------------------------------------------------------------------------------------------------
data_apresentacao[[i]] <- xml_find_all(pagina, '//td/text()[6]') %>%
xml_text() %>%
str_clean() %>%
str_trim()
#-----------------------------------------------------------------------------------------------------------
#                  AUTORIA
#-----------------------------------------------------------------------------------------------------------
autores <- ifelse(str_detect(textos, 'Autor: '),
ifelse(str_detect(textos, 'LocalizaÃ§Ã£o Atual'),
gsub('.*Autor: (.+) LocalizaÃ§Ã£o Atual.*', '\\1', textos),
removeWords(gsub('.*Autor: (.+)', '\\1', textos), c('Texto Original',
'Acompanhar MatÃ©ria',
'Norma.*',
'Data.*',
'AudiÃªncia.*'))),
NA) %>%
stringi::stri_trim_right()
autor[[i]] <- ifelse(str_detect(autores, 'Resultado'),
gsub('Resultado.*', '\\1', autores),
autores) %>%
str_trim()
#-----------------------------------------------------------------------------------------------------------
#                  LOCALIZACAO ATUAL
#-----------------------------------------------------------------------------------------------------------
loc_atual <- ifelse(str_detect(textos, 'LocalizaÃ§Ã£o Atual'),
gsub('.*LocalizaÃ§Ã£o Atual: (.+) Status.*', '\\1', textos),
NA)
localizacao_atual[[i]] <- ifelse(str_detect(textos, 'LocalizaÃ§Ã£o Atual:'), loc_atual, NA)
#-----------------------------------------------------------------------------------------------------------
#                     EMENTAS
#-----------------------------------------------------------------------------------------------------------
ementas[[i]] <- ifelse(str_detect(textos, 'Ementa'),
gsub('.*Ementa: (.+) ApresentaÃ§Ã£o.*', '\\1', textos))
#-----------------------------------------------------------------------------------------------------------
#                       STATUS
#-----------------------------------------------------------------------------------------------------------
status2 <- ifelse(str_detect(textos, 'Status'),
gsub('.*Status: (.+) Data Fim Prazo.*', '\\1', textos),
NA)
status[[i]] <- ifelse(str_detect(textos, 'Status:'), status2, NA)
#-----------------------------------------------------------------------------------------------------------
#                RESULTADO
#-----------------------------------------------------------------------------------------------------------
resultados <- ifelse(str_detect(textos, 'Resultado'),
ifelse(str_detect(textos, 'Data VotaÃ§Ã£o'),
gsub('.*Resultado: (.+) Data VotaÃ§Ã£o.*', '\\1', textos),
gsub('.*Resultado: (.+)', '\\1', textos)
),
NA)
resultados <- ifelse(str_detect(resultados, 'Data Da Ãltima TramitaÃ§Ã£o'),
gsub('Data Da Ãltima TramitaÃ§Ã£o.*', '\\1', resultados),
resultados)
resultado[[i]] <- str_remove_all(resultados, 'Texto Original') %>% str_trim()
print(i)
}
sapl_data <- tibble(num_projeto = unlist(num_projeto),
ementa = unlist(ementas),
data_apresentacao = unlist(data_apresentacao),
autor = unlist(autor),
localizacao_atual = unlist(localizacao_atual),
status = unlist(status),
resultado = unlist(resultado))
return(sapl_data)
}
tempo_inicial <- Sys.time()
sapl2021 <- sapl_scrap(URL = str_replace_all(string = 'https://sapl.al.ro.leg.br/materia/pesquisar-materia?page=PAGE&tipo=&ementa=&numero=&numeracao__numero_materia=&numero_protocolo=&ano=&o=&tipo_listagem=1&tipo_origem_externa=&numero_origem_externa=&ano_origem_externa=&data_origem_externa_0=&data_origem_externa_1=&local_origem_externa=&data_apresentacao_0=01%2F01%2FAAAA&data_apresentacao_1=31%2F12%2FAAAA&data_publicacao_0=&data_publicacao_1=&autoria__autor=&autoria__primeiro_autor=unknown&autoria__autor__tipo=&autoria__autor__parlamentar_set__filiacao__partido=&relatoria__parlamentar_id=&em_tramitacao=&tramitacao__unidade_tramitacao_destino=&tramitacao__status=&materiaassunto__assunto=&indexacao=',
pattern = 'AAAA', replacement = '2021'))
Sys.time() - tempo_inicial
tempo_inicial <- Sys.time()
sapl2020 <- sapl_scrap(URL = str_replace_all(string = 'https://sapl.al.ro.leg.br/materia/pesquisar-materia?page=PAGE&tipo=&ementa=&numero=&numeracao__numero_materia=&numero_protocolo=&ano=&o=&tipo_listagem=1&tipo_origem_externa=&numero_origem_externa=&ano_origem_externa=&data_origem_externa_0=&data_origem_externa_1=&local_origem_externa=&data_apresentacao_0=01%2F01%2FAAAA&data_apresentacao_1=31%2F12%2FAAAA&data_publicacao_0=&data_publicacao_1=&autoria__autor=&autoria__primeiro_autor=unknown&autoria__autor__tipo=&autoria__autor__parlamentar_set__filiacao__partido=&relatoria__parlamentar_id=&em_tramitacao=&tramitacao__unidade_tramitacao_destino=&tramitacao__status=&materiaassunto__assunto=&indexacao=',
pattern = 'AAAA', replacement = '2020'))
Sys.time() - tempo_inicial
tempo_inicial <- Sys.time()
sapl2019 <- sapl_scrap(URL = str_replace_all(string = 'https://sapl.al.ro.leg.br/materia/pesquisar-materia?page=PAGE&tipo=&ementa=&numero=&numeracao__numero_materia=&numero_protocolo=&ano=&o=&tipo_listagem=1&tipo_origem_externa=&numero_origem_externa=&ano_origem_externa=&data_origem_externa_0=&data_origem_externa_1=&local_origem_externa=&data_apresentacao_0=01%2F01%2FAAAA&data_apresentacao_1=31%2F12%2FAAAA&data_publicacao_0=&data_publicacao_1=&autoria__autor=&autoria__primeiro_autor=unknown&autoria__autor__tipo=&autoria__autor__parlamentar_set__filiacao__partido=&relatoria__parlamentar_id=&em_tramitacao=&tramitacao__unidade_tramitacao_destino=&tramitacao__status=&materiaassunto__assunto=&indexacao=',
pattern = 'AAAA', replacement = '2019'))
Sys.time() - tempo_inicial
sapl_data <- bind_rows(sapl2019, sapl2020, sapl2021)
# tratamento dos dados ----
for(i in 1: nrow(sapl_data)) {
if(grepl('PLO', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'PLO'
if(grepl('PLC', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'PLC'
if(grepl('PRE', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'PRE'
if(grepl('PEC', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'PEC'
if(grepl('VT', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'VT'
if(grepl('VP', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'VP'
if(grepl('IND', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'IND'
if(grepl('REQ', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'REQ'
if(grepl('ECM', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'ECM'
if(grepl('PDL', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'PDL'
}
sapl_data$data <- gsub(' De ', '', sapl_data$data_apresentacao) %>%
strptime(format = '%d %B %Y')
sapl_data <- sapl_data %>%
mutate(num_projeto = gsub('\\-.*', '', num_projeto),
data_apresentacao = format(lubridate::dmy(data_apresentacao), '%d/%m/%Y'),
mes_apresentacao = lubridate::month(data_apresentacao, label = TRUE, abbr = TRUE),
ano_apresentacao = as.character(substring(data_apresentacao, 7, 11)),
num_projeto = str_trim(num_projeto, side = 'right'))
saveRDS(sapl_data, file = 'dados_sapl.rds')
sapl_data %>% View()
sapl_data %>% count(resultado)
sapl_data %>% count(resultado) %>% View()
library(rvest)      # web scrapping
library(dplyr)      # manipular dados
library(stringr)    # manipular os textos
library(xml2)       # ler html
library(jbkmisc)
library(tm)
# o código de scrape a seguir serve tanto para PLO como PLC
# tipos de materia: PLO, PLC, VP
# uma_pagina = TRUE ou FALSE
#sapl_scrap <- function(URL, tipo_materia = NULL, uma_pagina = FALSE) {
sapl_scrap <- function(URL, uma_pagina = FALSE) {
# extraindo o numero total de paginas
num_total_pages <- ifelse(uma_pagina,
1,
str_replace(URL, 'page=PAGE&', '') %>%
read_html() %>%
xml_find_all('//nav/ul') %>%
xml_text() %>%
str_clean() %>%
str_match_all('[0-9]+') %>%
unlist() %>%
as.numeric() %>%
max())
# scrapping das ementas
num_projeto <- list()
data_apresentacao <- list()
localizacao_atual <- list()
autor <- list()
ementas <- list()
status <- list()
data_ultima_tram <- list()
resultado <- list()
for(i in 1:num_total_pages) {
url <- str_replace(URL, 'PAGE', as.character(i))
pagina <- read_html(url) %>% xml_root()
# numero de materia
nodes_link <- xml_find_all(pagina, '//td//a')
#num_projeto[[i]] <- xml_text(nodes_link)[str_detect(xml_text(nodes_link), tipo_materia)]
num_projeto[[i]] <- xml_text(nodes_link)[!(xml_text(nodes_link) %in% c('Texto Original', '', 'Acompanhar Matéria'))]
num_projeto[[i]] <- num_projeto[[i]][!str_detect(num_projeto[[i]], pattern = '\n')]
# textos
textos <- xml_find_all(pagina, '//td') %>%
xml_text() %>%
str_clean()
textos <- textos[textos != ' ']
textos <- textos[-1]
#-----------------------------------------------------------------------------------------------------------
#                 data de apresentacao
#-----------------------------------------------------------------------------------------------------------
data_apresentacao[[i]] <- xml_find_all(pagina, '//td/text()[6]') %>%
xml_text() %>%
str_clean() %>%
str_trim()
#-----------------------------------------------------------------------------------------------------------
#                  AUTORIA
#-----------------------------------------------------------------------------------------------------------
autores <- ifelse(str_detect(textos, 'Autor: '),
ifelse(str_detect(textos, 'Localização Atual'),
gsub('.*Autor: (.+) Localização Atual.*', '\\1', textos),
removeWords(gsub('.*Autor: (.+)', '\\1', textos), c('Texto Original',
'Acompanhar Matéria',
'Norma.*',
'Data.*',
'Audiência.*'))),
NA) %>%
stringi::stri_trim_right()
autor[[i]] <- ifelse(str_detect(autores, 'Resultado'),
gsub('Resultado.*', '\\1', autores),
autores) %>%
str_trim()
#-----------------------------------------------------------------------------------------------------------
#                  LOCALIZACAO ATUAL
#-----------------------------------------------------------------------------------------------------------
loc_atual <- ifelse(str_detect(textos, 'Localização Atual'),
gsub('.*Localização Atual: (.+) Status.*', '\\1', textos),
NA)
localizacao_atual[[i]] <- ifelse(str_detect(textos, 'Localização Atual:'), loc_atual, NA)
#-----------------------------------------------------------------------------------------------------------
#                     EMENTAS
#-----------------------------------------------------------------------------------------------------------
ementas[[i]] <- ifelse(str_detect(textos, 'Ementa'),
gsub('.*Ementa: (.+) Apresentação.*', '\\1', textos))
#-----------------------------------------------------------------------------------------------------------
#                       STATUS
#-----------------------------------------------------------------------------------------------------------
status2 <- ifelse(str_detect(textos, 'Status'),
gsub('.*Status: (.+) Data Fim Prazo.*', '\\1', textos),
NA)
status[[i]] <- ifelse(str_detect(textos, 'Status:'), status2, NA)
#-----------------------------------------------------------------------------------------------------------
#                RESULTADO
#-----------------------------------------------------------------------------------------------------------
resultados <- ifelse(str_detect(textos, 'Resultado'),
ifelse(str_detect(textos, 'Data Votação'),
gsub('.*Resultado: (.+) Data Votação.*', '\\1', textos),
gsub('.*Resultado: (.+)', '\\1', textos)
),
NA)
resultados <- ifelse(str_detect(resultados, 'Data Da Última Tramitação'),
gsub('Data Da Última Tramitação.*', '\\1', resultados),
resultados)
resultado[[i]] <- str_remove_all(resultados, 'Texto Original') %>% str_trim()
print(i)
}
sapl_data <- tibble(num_projeto = unlist(num_projeto),
ementa = unlist(ementas),
data_apresentacao = unlist(data_apresentacao),
autor = unlist(autor),
localizacao_atual = unlist(localizacao_atual),
status = unlist(status),
resultado = unlist(resultado))
return(sapl_data)
}
tempo_inicial <- Sys.time()
sapl2019 <- sapl_scrap(URL = str_replace_all(string = 'https://sapl.al.ro.leg.br/materia/pesquisar-materia?page=PAGE&tipo=&ementa=&numero=&numeracao__numero_materia=&numero_protocolo=&ano=&o=&tipo_listagem=1&tipo_origem_externa=&numero_origem_externa=&ano_origem_externa=&data_origem_externa_0=&data_origem_externa_1=&local_origem_externa=&data_apresentacao_0=01%2F01%2FAAAA&data_apresentacao_1=31%2F12%2FAAAA&data_publicacao_0=&data_publicacao_1=&autoria__autor=&autoria__primeiro_autor=unknown&autoria__autor__tipo=&autoria__autor__parlamentar_set__filiacao__partido=&relatoria__parlamentar_id=&em_tramitacao=&tramitacao__unidade_tramitacao_destino=&tramitacao__status=&materiaassunto__assunto=&indexacao=',
pattern = 'AAAA', replacement = '2019'))
Sys.time() - tempo_inicial
tempo_inicial <- Sys.time()
sapl2020 <- sapl_scrap(URL = str_replace_all(string = 'https://sapl.al.ro.leg.br/materia/pesquisar-materia?page=PAGE&tipo=&ementa=&numero=&numeracao__numero_materia=&numero_protocolo=&ano=&o=&tipo_listagem=1&tipo_origem_externa=&numero_origem_externa=&ano_origem_externa=&data_origem_externa_0=&data_origem_externa_1=&local_origem_externa=&data_apresentacao_0=01%2F01%2FAAAA&data_apresentacao_1=31%2F12%2FAAAA&data_publicacao_0=&data_publicacao_1=&autoria__autor=&autoria__primeiro_autor=unknown&autoria__autor__tipo=&autoria__autor__parlamentar_set__filiacao__partido=&relatoria__parlamentar_id=&em_tramitacao=&tramitacao__unidade_tramitacao_destino=&tramitacao__status=&materiaassunto__assunto=&indexacao=',
pattern = 'AAAA', replacement = '2020'))
Sys.time() - tempo_inicial
tempo_inicial <- Sys.time()
sapl2021 <- sapl_scrap(URL = str_replace_all(string = 'https://sapl.al.ro.leg.br/materia/pesquisar-materia?page=PAGE&tipo=&ementa=&numero=&numeracao__numero_materia=&numero_protocolo=&ano=&o=&tipo_listagem=1&tipo_origem_externa=&numero_origem_externa=&ano_origem_externa=&data_origem_externa_0=&data_origem_externa_1=&local_origem_externa=&data_apresentacao_0=01%2F01%2FAAAA&data_apresentacao_1=31%2F12%2FAAAA&data_publicacao_0=&data_publicacao_1=&autoria__autor=&autoria__primeiro_autor=unknown&autoria__autor__tipo=&autoria__autor__parlamentar_set__filiacao__partido=&relatoria__parlamentar_id=&em_tramitacao=&tramitacao__unidade_tramitacao_destino=&tramitacao__status=&materiaassunto__assunto=&indexacao=',
pattern = 'AAAA', replacement = '2021'))
Sys.time() - tempo_inicial
sapl_data <- bind_rows(sapl2019, sapl2020, sapl2021)
# tratamento dos dados ----
for(i in 1: nrow(sapl_data)) {
if(grepl('PLO', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'PLO'
if(grepl('PLC', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'PLC'
if(grepl('PRE', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'PRE'
if(grepl('PEC', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'PEC'
if(grepl('VT', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'VT'
if(grepl('VP', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'VP'
if(grepl('IND', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'IND'
if(grepl('REQ', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'REQ'
if(grepl('ECM', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'ECM'
if(grepl('PDL', as.character(sapl_data$num_projeto[i]), fixed = TRUE)) sapl_data$projeto[i] <- 'PDL'
}
sapl_data$data <- gsub(' De ', '', sapl_data$data_apresentacao) %>%
strptime(format = '%d %B %Y')
sapl_data <- sapl_data %>%
mutate(num_projeto = gsub('\\-.*', '', num_projeto),
data_apresentacao = format(lubridate::dmy(data_apresentacao), '%d/%m/%Y'),
mes_apresentacao = lubridate::month(data_apresentacao, label = TRUE, abbr = TRUE),
ano_apresentacao = as.character(substring(data_apresentacao, 7, 11)),
num_projeto = str_trim(num_projeto, side = 'right'))
setwd("~/GitHub/painel_legislativo")
saveRDS(sapl_data, file = 'dados_sapl.rds')
sapl_data <- readRDS(url('https://github.com/caio-alero/painel_legislativo/blob/main/dados_sapl.rds?raw=TRUE'))
library(reshape2)
library(DT)
library(echarts4r)
library(countup)
library(shiny)
library(dplyr)
library(lubridate)
library(stringr)
library(summaryBox)
library(thematic)
library(showtext)
library(bslib)
library(shinydashboard)
library(OSUICode)
library(shinyWidgets)
library(waiter)
library(tablerDash)
options(encoding = "UTF-8")
# dados das matérias ----
agrupamento_status <- read.table('agrupamento_status.txt', sep = '\t', header = TRUE)
sapl_data <- readRDS(url('https://github.com/caio-alero/painel_legislativo/blob/main/dados_sapl.rds?raw=TRUE'))
sapl_data <- readRDS(url('https://github.com/caio-alero/painel_legislativo/raw/main/dados_sapl.rds'))
download.file('https://github.com/caio-alero/painel_legislativo/raw/main/dados_sapl.rds')
download.file('https://github.com/caio-alero/painel_legislativo/raw/main/dados_sapl.rds', destfile = 'dados.rds')
readRDS(url('https://drive.google.com/file/d/1QtAjxj62r_veTASLTGHtXeuIdahNeKhe/view?usp=sharing'))
readRDS(url('https://drive.google.com/file/d/1QtAjxj62r_veTASLTGHtXeuIdahNeKhe/view?raw=TRUE'))
sapl_data <- download.file('https://drive.google.com/file/d/1QtAjxj62r_veTASLTGHtXeuIdahNeKhe/view?usp=sharing')
sapl_data <- download.file('https://drive.google.com/file/d/1QtAjxj62r_veTASLTGHtXeuIdahNeKhe/view?usp=sharing', destfile = 'dados.rds')
dados
readRDS('dados.rds')
dados <- readRDS("~/GitHub/painel_legislativo/dados.rds")
sapl_data <- download.file('https://drive.google.com/file/d/1QtAjxj62r_veTASLTGHtXeuIdahNeKhe&export=download', destfile = 'dados.rds')
sapl_data <- readRDS(url('https://github.com/caio-alero/painel_legislativo/raw/main/dados_sapl.rds'))
sapl_data <- readRDS(url('raw.githubusercontent.com/caio-alero/painel_legislativo/raw/main/dados_sapl.rds'))
sapl_data <- readRDS(url('raw.githubusercontent.com/caio-alero/painel_legislativo/main/dados_sapl.rds?raw=TRUE'))
sapl_data <- readRDS(url('raw.githubusercontent.com/caio-alero/painel_legislativo/main/dados_sapl.rds'))
sapl_data <- readRDS(url('raw.githubusercontent.com/caio-alero/painel_legislativo/main/dados_sapl.rds'))
sapl_data <- readRDS(url('raw.githubusercontent.com/caio-alero/painel_legislativo/master/dados_sapl.rds'))
sapl_data <- readRDS(url('raw.githubusercontent.com/caio-alero/painel_legislativo/dados_sapl.rds'))
curl
install.packages('curl')
library(curl)
readRDS(curl('https://github.com/caio-alero/painel_legislativo/raw/main/dados_sapl.rds'))
remotes::install_github("achubaty/amc")
library('achubaty/amc')
sapl_data <- readRDS(curl('https://github.com/caio-alero/analise_sapl/raw/main/dados_sapl.rds'))
sapl_data <- readRDS(curl('https://github.com/caio-alero/analise_sapl/raw/main/dados_sapl.rds?raw=TRUE'))
sapl_data <- readRDS(curl('https://github.com/caio-alero/analise_sapl/raw/main/dados_sapl.rds&raw=TRUE'))
sapl_data <- readRDS(curl('https://github.com/caio-alero/analise_sapl/raw/main/dados_sapl.rds?raw=TRUE'))
sapl_data <- readRDS(curl('https://github.com/caio-alero/analise_sapl/raw/main/dados_sapl.rds?raw=TRUE'))
sapl_data <- readRDS(url('https://github.com/caio-alero/analise_sapl/raw/main/dados_sapl.rds?raw=TRUE'))
sapl_data
sapl_data <- readRDS(url('https://github.com/caio-alero/analise_sapl/raw/main/dados_sapl.rds?raw=TRUE'))
sapl_data
runApp()
runApp()
runApp()
runApp()
sapl_data <- readRDS(url('https://github.com/caio-alero/analise_sapl/raw/main/dados_sapl.rds?raw=TRUE'))
sapl_data %>%
# filter(projeto %in% input$tipo,
#        ano_apresentacao %in% input$data) %>%
select(num_projeto, autor, ementa, data, localizacao_atual, status) %>%
mutate(data = as.Date(data, '%d/%m/%y')) %>%
datatable(rownames = FALSE,
style = 'bootstrap4',
options = list(paging = TRUE,
scrollY = TRUE,
#dom = 'ftp',
pagelength = 10,
searchHighlight = TRUE,
search = list(regex = TRUE),
language = list(url = '//cdn.datatables.net/plug-ins/1.10.11/i18n/Portuguese-Brasil.json')
# initComplete = JS(
#   "function(settings, json) {",
#   "$(this.api().table().header()).css({'background-color': '#208ffa', 'color': '#fff'});",
#   "}")
),
colnames = c('Matéria', 'Autoria', 'Ementa', 'Data de apresentação', 'Localização atual', 'Status atual'))
library(reshape2)
library(DT)
library(echarts4r)
library(countup)
library(shiny)
library(dplyr)
library(lubridate)
library(stringr)
library(summaryBox)
library(thematic)
library(showtext)
library(bslib)
library(shinydashboard)
library(OSUICode)
library(shinyWidgets)
library(waiter)
library(tablerDash)
options(encoding = "UTF-8")
#source('webscrapping_sessoes.R', local = TRUE)
# dados das matérias ----
agrupamento_status <- read.table('agrupamento_status.txt', sep = '\t', header = TRUE)
sapl_data <- readRDS(url('https://github.com/caio-alero/analise_sapl/raw/main/dados_sapl.rds?raw=TRUE'))
sapl_data <- merge(sapl_data, agrupamento_status, by.y = 'status')
sapl_data$Grupo <- recode_factor(as.factor(sapl_data$Grupo),
'1' = 'Proposição Aprovada',
'2' = 'Proposição Rejeitada',
'3' = 'Em tramitação',
'4' = 'Proposição Retirada',
'NA' = 'NA')
sapl_data %>%
# filter(projeto %in% input$tipo,
#        ano_apresentacao %in% input$data) %>%
select(num_projeto, autor, ementa, data, localizacao_atual, status) %>%
mutate(data = as.Date(data, '%d/%m/%y')) %>%
datatable(rownames = FALSE,
style = 'bootstrap4',
options = list(paging = TRUE,
scrollY = TRUE,
#dom = 'ftp',
pagelength = 10,
searchHighlight = TRUE,
search = list(regex = TRUE),
language = list(url = '//cdn.datatables.net/plug-ins/1.10.11/i18n/Portuguese-Brasil.json')
# initComplete = JS(
#   "function(settings, json) {",
#   "$(this.api().table().header()).css({'background-color': '#208ffa', 'color': '#fff'});",
#   "}")
),
colnames = c('Matéria', 'Autoria', 'Ementa', 'Data de apresentação', 'Localização atual', 'Status atual'))
runApp()
runApp()
